<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Minghe Shen</title>
  
  <meta name="author" content="Minghe Shen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.jpg">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Minghe Shen</name>
              </p>
              <p>
              Ph.D. student from the IIML Lab at the University College London,  Department of Electronic and Electrical Engineering, advised by Prof. <a href="https://profiles.ucl.ac.uk/7661-miguel-rodrigues">Miguel Rodrigues</a>.
              </p>

              <p style="text-align:center">
                <a href="minghe.shen.24@ucl.ac.uk">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=b-63heQAAAAJ&hl=en"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/minghe-shen/"> Linkedin </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:80%;max-width:100%" alt="profile photo" src="images/profile.jpg">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Experiences</heading>
            <p>
	      <li style="margin: 5px;" >
                <b>2025-10 --> 2026-01:</b> Machine Learning Engineer Internship @ Advanced AI Lab, Samsung R&D Institute UK (SRUK).
            <li style="margin: 5px;" >
                <b>2024-10 --> 2025-03:</b> Teaching Assistant in Applied Machine Learning Systems, University College London.
            </li>
            <li style="margin: 5px;" >
                <b>2024-10 --> 2025-01:</b> Teaching Assistant in Data Acquisition and Processing Systems Teaching Assistant in Data Acquisition and Processing Systems, University College London.
            </li>
            <li style="margin: 5px;" >
                <b>2024-10 --> now:</b> Ph.D. student, IIML Lab, Department of Electronic and Electrical Engineering, University College London, advised by Prof. Miguel Rodrigues. Topics: AI Reliability; Large Language Models; Machine Learning; Multimodal Learning.
            </li>
            <li style="margin: 5px;" >
                <b>2020-09 --> 2023-06:</b> M.S. student, Northwestern Polytechnical University, China. Topics: Compressed Sensing; Machine Learning; Imaging Systems.
            </li>
            </p>
          </td>
        </tr>
      </tbody></table>

      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading> Selected Publications </heading>
              <!-- <p>
                * indicates equal contribution
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody></tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img class="zoomable" style="width:100%;height:auto;" src="images/NHT.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Noisy but Valid: Robust Statistical Evaluation of LLMs with Imperfect Judges</papertitle>
              <br>
              Chen Feng<sup>†</sup>, <strong>Minghe Shen</strong><sup>†</sup>, 
              Ananth Balashankar, Carsten Gerner-Beuerle, Miguel R. D. Rodrigues
              <br>
              <sup>†</sup> Equal contribution.
              ICLR, 2026
              <br>
              <br>
              <a href="https://www.arxiv.org/abs/2601.20913">[Paper]</a>
              <!-- <a href="https://2j472no.github.io/xNet/">[Project]</a> -->
              <br>
              <p> Reliable certification of Large Language Models (LLMs)—verifying that failure
              rates are below a safety threshold—is critical yet challenging. While "LLM-asa-Judge" offers scalability, judge imperfections, noise, and bias can invalidate
              statistical guarantees. We introduce a "Noisy but Valid" hypothesis testing framework to address this. By leveraging a small human-labelled calibration set to
              estimate the judge's True Positive and False Positive Rates (TPR/FPR), we derive
              a variance-corrected critical threshold applied to a large judge-labelled dataset.
              Crucially, our framework theoretically guarantees finite-sample Type-I error control (validity) despite calibration uncertainty. This distinguishes our work from
              Prediction-Powered Inference (PPI), positioning our method as a diagnostic tool
              that explicitly models judge behavior rather than a black-box estimator. Our contributions include: (1) Theoretical Guarantees: We derive the exact conditions under
              which noisy testing yields higher statistical power than direct evaluation; (2) Empirical Validation: Experiments on Jigsaw Comment, Hate Speech and SafeRLHF
              confirm our theory; (3) The Oracle Gap: We reveal a significant performance gap
              between practical methods and the theoretical "Oracle" (perfectly known judge
              parameters), quantifying the cost of estimation. Specifically, we provide the first
              systematic treatment of the imperfect-judge setting, yielding interpretable diagnostics of judge reliability and clarifying how evaluation power depends on judge
              quality, dataset size, and certification levels. Together, these results sharpen understanding of statistical evaluation with LLM judges, and highlight trade-offs among
              competing inferential tools.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
            <img class="zoomable" style="width:100%;height:auto;" src="images/MTC.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>MTC-CSNet: Marrying Transformer and Convolution for Image Compressed Sensing</papertitle>
              <br>
              <strong>Minghe Shen</strong>, Hongping Gan, Chunyan Ma, Chao Ning, Hongqi Li, and Feng Liu
              <br>
              IEEE Transactions on Cybernetics, 2024
              <br>
              <a href="https://ieeexplore.ieee.org/document/10445137">[Paper]</a>
              <!-- <a href="https://github.com/ICSResearch/LP">[Code]</a> -->
              <br>
              <p> Image compressed sensing (ICS) has been extensively applied in various imaging domains due to its capability to sample and reconstruct images at subNyquist sampling rates. The current predominant approaches in ICS, specifically pure convolutional networks (ConvNets)-based ICS methods, have demonstrated their effectiveness in capturing local features for image recovery. Simultaneously, the Transformer architecture has gained significant attention due to its capability to model global correlations among image features. Motivated by these insights, we propose a novel hybrid network for ICS, named MTC-CSNet, which effectively combines the strengths of both ConvNets and Transformer architectures in capturing local and global image features to achieve high-quality image recovery. Particularly, MTC-CSNet is a dual-path framework that consists of a ConvNets-based recovery branch and a Transformer-based recovery branch. Along the ConvNets-based recovery branch, we design a lightweight scheme to capture the local features in natural images. Meanwhile, we implement a Transformer-based recovery branch to iteratively model the global dependencies among image patches. Ultimately, the ConvNets-based and Transformer-based recovery branches collaborate through a bridging unit, facilitating the adaptive transmission and fusion of informative features for image reconstruction. Extensive experimental results demonstrate that our proposed MTC-CSNet surpasses the state-of-the-art methods on various public datasets. The code and models are publicly available at MTC-CSNet. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
            <img class="zoomable" style="width:100%;height:auto;" src="images/TCS.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>From patch to pixel: A transformer-based hierarchical framework for compressive image sensing</papertitle>
              <br>
              Hongping Gan, <strong>Minghe Shen</strong>, Yi Hua , Chunyan Ma, and Tao Zhang
              <br>
              IEEE Transactions on Computational Imaging, 2023
              <br>
              <a href="https://ieeexplore.ieee.org/document/10049603">[Paper]</a>
              <!-- <a href="https://github.com/ICSResearch/LP">[Code]</a> -->
              <br>
              <p> The convolutional neural network (CNN)-based reconstruction methods have dominated the compressive sensing
              (CS) in recent years. However, existing CNN-based approaches
              show potential restrictions in capturing non-local similarity of images, because of the intrinsic characteristic of convolutional layers,
              i.e., locality and weight sharing. In parallel, the emerging Transformer architecture shows fine capacity in modeling long-distance
              correlations onto embedded tokens for language and images. Yet
              vanilla Transformer does not exceed CNN-based networks considerably but shows roughly comparable performance, and the culprit
              can be the missing of sophisticated inductive bias regarding the
              local image structures. In this article, to eliminate the restrictions
              of the aforementioned paradigms, we propose a Transformer-based
              hierarchical framework, dubbed TCS-Net, for compressive image
              sensing (or image compressive sensing) with a patch-to-pixel
              manner. Concretely, the proposed TCS-Net consists of an image
              acquisition module and a reconstruction module (includes two key
              decoding phases: a patch-wise decoding phase and a pixel-wise decoding phase). The acquisition module can implement data-driven
              image sampling by jointly learning with the decoding phases. By adjusting the Transformer architecture to the patch-to-pixel
              multi-stage pattern, our reconstruction module can gradually decode the CS measurements from the patch-wise outlines to the pixelwise textures, thereby building a high-precision mapping for image
              reconstruction. Extensive experiments on several datasets verify
              that the proposed TCS-Net outperforms existing state-of-the-art
              image CS methods by considerable margins. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
            <img class="zoomable" style="width:100%;height:auto;" src="images/TransCS.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>TransCS: A transformer-based hybrid architecture for image compressed sensing</papertitle>
              <br>
              <strong>Minghe Shen</strong>, Hongping Gan, Chao Ning, Yi Hua, and Tao Zhang
              <br>
              IEEE Transactions on Image Processing, 2023
              <br>
              <a href="https://ieeexplore.ieee.org/document/9934025">[Paper]</a>
              <!-- <a href="https://github.com/ICSResearch/LP">[Code]</a> -->
              <br>
              <p> Well-known compressed sensing (CS) is widely used in image acquisition and reconstruction. However, accurately reconstructing images from measurements at low sampling rates remains a considerable challenge. In this paper, we propose a novel Transformer-based hybrid architecture (dubbed TransCS) to achieve high-quality image CS. In the sampling module, TransCS adopts a trainable sensing matrix strategy that gains better image reconstruction by learning the structural information from the training images. In the reconstruction module, inspired by the powerful long-distance dependence modelling capacity of the Transformer, a customized iterative shrinkage-thresholding algorithm (ISTA)-based Transformer backbone that iteratively works with gradient descent and soft threshold operation is designed to model the global dependency among image subblocks. Moreover, the auxiliary convolutional neural network (CNN) is introduced to capture the local features of images. Therefore, the proposed hybrid architecture that integrates the customized ISTA-based Transformer backbone with CNN can gain high-performance reconstruction for image compressed sensing. The experimental results demonstrate that our proposed TransCS obtains superior reconstruction quality and noise robustness on several public benchmark datasets compared with other state-of-the-art methods. Our code is available on TransCS. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
            <img class="zoomable" style="width:100%;height:auto;" src="images/LP.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning-based padding: From connectivity on data borders to data padding</papertitle>
              <br>
              Chao Ning, Hongping Gan, <strong>Minghe Shen</strong>, Tao Zhang
              <br>
              Engineering Applications of Artificial Intelligence, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197623002324">[Paper]</a> <a href="https://github.com/ICSResearch/LP">[Code]</a>
              <br>
              <p> We propose learning based padding that predicts border values from feature map context using lightweight convolution (LPC) and attention (LPA) modules, providing a generic plug and play replacement for zero padding that consistently improves accuracy on image classification and semantic segmentation across diverse backbones. </p>
            </td>
          </tr>


        </table>

          
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> SpringGX scholarship (2023-2026) </li>
              </p>
            </td>
          </tr>
        </tbody></table>  -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b> ICLR, ICCV, ACL
              </li>
              <li style="margin: 5px;"> 
                <b>Journal Reviewer:</b> IEEE TIP, IEEE TCI
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
 
<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=L9EQlZkj5iCdWBMkJkgi98zY_ACS8WXMtmi-BflmwK8"></script>
	  </div>        
	  <br>
	    &copy; Minghe Shen | Last updated: 21 Feb, 2026
</center></p>





<div class="lb" id="lb"><img alt=""></div>

<script>
  const lb = document.getElementById('lb');
  const lbImg = lb.querySelector('img');

  document.addEventListener('click', e => {
    const img = e.target.closest('img.zoomable');
    if (img) {
      lbImg.src = img.dataset.full || img.src; // 有 data-full 就用原图
      lb.classList.add('open');
    } else if (e.target === lb) {
      lb.classList.remove('open');
    }
  });

  document.addEventListener('keydown', e => {
    if (e.key === 'Escape') lb.classList.remove('open');
  });
</script>
</body>

</html>
